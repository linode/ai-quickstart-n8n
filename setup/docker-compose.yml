services:

  #--------------------------------------------
  # Caddy - Reverse Proxy with Auto HTTPS
  #--------------------------------------------
  caddy:
    image: caddy:2-alpine
    container_name: caddy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    environment:
      - SUBDOMAIN=${SUBDOMAIN}
      - DOMAIN_NAME=${DOMAIN_NAME}
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - caddy_data:/data
      - caddy_config:/config
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://127.0.0.1:2019/config/"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    depends_on:
      - n8n

  #--------------------------------------------
  # n8n - AI Workflow Automation
  #--------------------------------------------
  n8n:
    image: n8nio/n8n:latest
    container_name: n8n
    restart: unless-stopped
    ports:
      - "127.0.0.1:5678:5678"
    environment:
      - SUBDOMAIN=${SUBDOMAIN}
      - DOMAIN_NAME=${DOMAIN_NAME}
      - N8N_HOST=${SUBDOMAIN}.${DOMAIN_NAME}
      - WEBHOOK_URL=https://${SUBDOMAIN}.${DOMAIN_NAME}/
      - N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=true
      - N8N_PORT=5678
      - N8N_PROTOCOL=https
      - N8N_PROXY_HOPS=1
      - N8N_RUNNERS_ENABLED=true
      - NODE_ENV=production
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=pgvector
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=n8n
      - DB_POSTGRESDB_USER=n8n
      - DB_POSTGRESDB_PASSWORD=n8n
      - N8N_PERSONALIZATION_ENABLED=false
    volumes:
      - n8n_data:/home/node/.n8n
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://127.0.0.1:5678/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    depends_on:
      - pgvector

  #--------------------------------------------
  # vLLM - OpenAI-Compatible LLM Inference
  #--------------------------------------------
  vllm:
    image: vllm/vllm-openai:nightly
    container_name: vllm
    restart: unless-stopped
    shm_size: 8g
    ports:
      - "127.0.0.1:8000:8000"
    volumes:
      - hf_data:/root/.cache/huggingface
    environment:
      - HF_HOME=/root/.cache/huggingface
    command:
      - openai/gpt-oss-20b
      - --gpu-memory-utilization=0.75
      - --max-model-len=12288
      - --max-num-seqs=2
      - --enable-auto-tool-choice
      - --tool-call-parser=openai 
      - --reasoning-parser=openai_gptoss
      - --enable-prompt-tokens-details
    healthcheck:
      test: ["CMD", "curl", "-f", "-s", "http://127.0.0.1:8000/v1/models"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 180s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]

  embedding:
    image: vllm/vllm-openai:nightly
    container_name: embedding
    restart: unless-stopped
    shm_size: 1g
    ports:
      - "127.0.0.1:8001:8001"
    volumes:
      - hf_data:/root/.cache/huggingface
    command:
      - BAAI/bge-m3
      - --gpu-memory-utilization=0.1
      - --dtype=bfloat16
      - --port=8001
    healthcheck:
      test: ["CMD", "curl", "-f", "-s", "http://127.0.0.1:8001/v1/models"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 120s 
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]

  reranker:
    image: vllm/vllm-openai:nightly
    container_name: reranker
    restart: unless-stopped
    shm_size: 1g
    ports:
      - "127.0.0.1:8002:8002"
    volumes:
      - hf_data:/root/.cache/huggingface
    command:
      - BAAI/bge-reranker-v2-m3
      - --gpu-memory-utilization=0.1
      - --dtype=bfloat16
      - --trust-remote-code
      - --port=8002
    healthcheck:
      test: ["CMD", "curl", "-f", "-s", "http://127.0.0.1:8002/v1/models"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 120s 
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]


  #--------------------------------------------
  # pgvector - PostgreSQL with pgvector extension
  #--------------------------------------------
  pgvector:
    image: pgvector/pgvector:0.8.1-pg18-bookworm
    container_name: pgvector
    restart: unless-stopped
    ports:
      - "127.0.0.1:5432:5432"
    environment:
      - POSTGRES_USER=n8n
      - POSTGRES_PASSWORD=n8n
      - POSTGRES_DB=n8n
    volumes:
      - pgvector_base:/var/lib/postgresql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U n8n -d n8n"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  caddy_data:
  caddy_config:
  n8n_data:
  hf_data:
  pgvector_base:
